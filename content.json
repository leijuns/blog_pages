{"pages":[{"title":"分类","text":"","link":"/categories/index.html"}],"posts":[{"title":"扩展巴科斯范式","text":"扩展巴科斯-瑙尔范式(EBNF, Extended Backus–Naur Form)是表达作为描述计算机编程语言和形式语言的正规方式的上下文无关文法的元语法(metalanguage)符号表示法 —— wikipedia。 白话就是定义的一种用来表示一种语言的语法形式的一种表示方法。 例子： EBNF 定义 12345678910111213141516(* a simple program in EBNF − Wikipedia *)program = 'PROGRAM' , white space , identifier , white space , 'BEGIN' , white space , { assignment , \";\" , white space } , 'END.' ;identifier = alphabetic character , [ { alphabetic character | digit } ] ;number = [ \"-\" ] , digit , [ { digit } ] ;string = '\"' , { all characters − '\"' } , '\"' ;assignment = identifier , \":=\" , ( number | identifier | string ) ;alphabetic character = \"A\" | \"B\" | \"C\" | \"D\" | \"E\" | \"F\" | \"G\" | \"H\" | \"I\" | \"J\" | \"K\" | \"L\" | \"M\" | \"N\" | \"O\" | \"P\" | \"Q\" | \"R\" | \"S\" | \"T\" | \"U\" | \"V\" | \"W\" | \"X\" | \"Y\" | \"Z\" ;digit = \"0\" | \"1\" | \"2\" | \"3\" | \"4\" | \"5\" | \"6\" | \"7\" | \"8\" | \"9\" ;white space = ? white space characters ? ;all characters = ? all visible characters ? ; 对应符合语法的程序 12345678910PROGRAM DEMO1 BEGIN A0:=3; B:=45; H:=-100023; C:=A; D123:=B34A; BABOON:=GIRAFFE; TEXT:=\"Hello world!\";END. 1. 可用的符号表 用途 符号表示 定义 = 串接 , 终止 ; 分隔 | 可选 [ … ] 重复 { … } 分组 ( … ) 双引号 “ … “ 单引号 ‘ … ‘ 注释 (* … *) 特殊序列 ? … ? 除外 - 2. 符号表示意义 , 符号 串接。连接字符串或者关键字的内容。如: 12zero = \"0\";natural number = \"1\" , \"2\" , \"3\" , \"4\" , \"5\" , \"6\" , \"7\" , \"8\" , \"9\", zero; natural number 将 zero 和 1-9 连接起来，可表示 0-9 之间的数 | 符号 分隔符号，等价于或。如 digit excluding zero = &quot;1&quot; | &quot;2&quot; | &quot;3&quot; | &quot;4&quot; | &quot;5&quot; | &quot;6&quot; | &quot;7&quot; | &quot;8&quot; | &quot;9&quot; ; 意味着 digit excluding zero 可以是 1-9 中的任意自然数。 [...] 符号 表示可选符号。与常规编程语言中的可选不太一样，此处可选还与次数有关。如： 1cc = 3 * [\"A\"], \"C\"; 可表示的字符串 1cc: C AC AAC AAAC {...} 符号 表示重复，与正则中的 . 意义一致，表可重复0次或多次。 如： 1dd = {\"A\"}, \"D\"; 可表示的字符串 1dd: D AD AAD AAAD AAAAD etc.","link":"/2019/12/24/EBNF/"},{"title":"Git rebase 基础用法","text":"git rebase 被翻译为变基，该命令的作用就是整理提交历史，效果是使得提交历史变成连续的，没有分叉。在团队开发时，经常需要进行合并，我们知道，一般使用 git pull 或 git merge 合并远程代码，合并时会优先使用快速合并，若不能快速合并则会采取三方合并，会添加一个 commit，commit 记录了被合并的两个 parent。 其实合并的方式不止默认的这两种方式，rebase/squash 等合并方式更是可以带来干净整洁的提交历史。 git merge通常合并分支我们有两种方法，merge 和 rebase，先看看在使用 merge 时合并分支的效果下图中，灰色表示 commit 橙色表示分支 使用 git merge 将 experiment 合并到 master 后，提交历史变为了： 图示中的这种合并方式称为 三方合并，将两个分支的最新提交与和两个分支的最近共同祖先进行合并，这种合并方式会生成一个新的 commit，通过 git cat-file 查看该 commit 可发现其包含两个 parent，分别为两个分支的最新提交。 git rebase用法： 12345git rebase [-i | --interactive] [&lt;options&gt;] [--exec &lt;cmd&gt;] [--onto &lt;newbase&gt; | --keep-base] [&lt;upstream&gt; [&lt;branch&gt;]]git rebase [-i | --interactive] [&lt;options&gt;] [--exec &lt;cmd&gt;] [--onto &lt;newbase&gt;] --root [&lt;branch&gt;]git rebase (--continue | --skip | --abort | --quit | --edit-todo | --show-current-patch) 同上面的例子相同，如果使用 git rebase 合并分支 12$ git checkout experiment$ git rebase master 这里 git rebase master 与 git rebase master experiment 是等效的。默认的目标分支就是当前分支。 合并时，master 为基底分支，当前分支是 experiment，两者的最近共同祖先是 c2。合并时的步骤是： 将当前分支相对与祖先分支的全部提交提取为零时文件。 将当前分支指向基底分支指向的 commit，然后将零时文件记录的修改依次应用。 重应用零时文件的内容虽与原来相同，但是会在当前分支上重新提交，commit 信息和原来不同。 最后将 experiment merge 到 master 后得到一条完美的提交历史 12$ git checkout master$ git merge experiment 删除提交git rebase 还可以删除一定范围内的提交如分支历史为 1E---F---G---H---I---J topicA 如果使用命令 1git rebase --onto topicA~5 topicA~3 topicA –onto &lt;newbase&gt; 选项表示以&lt;newbase&gt;为重放差异的基础。会将当前分支重置为 &lt;newbase&gt;，相当于 git reset --hard &lt;newbase&gt; 。 该命令的意思是找出 topicA~3 和 topicA 的差异，并以 topicA~5 为基础重放，操作的分支为 topicA。操作结果会删除 F 和 G 提交，最后提交历史变成： 1E---H&apos;---I&apos;---J&apos; topicA 其中 H’/I’/J’ 是原 H/I/J 的新版本","link":"/2020/04/14/Git-rebase/"},{"title":"微前端","text":"技术圈是比较爱炒概念的，中台、微服务、DDD一时都变成比较热门的话题，微前端作为微服务的一种自然也免不了俗。在我看来，大多数情况下大多数公司都用不上微前端。当然微前端不是什么新技术，只是为了解决实际问题的一种方法。微前端这三个字听起来不明所以，实际上只是将项目打散，变成若干小项目的合集，使用一种方案使得在多个项目之前平滑切换的方法。 为什么需要微前端前面说过，大多数情况下我们是不需要微前端的，通过清晰的组件划分，部分情况下使用 iframe 嵌入就能解决绝大部分问题。但是微前端对下面的问题解决起来更有优势： 迭代日积月累导致维护困难一个生命周期超长的软件，必然产生出一个体积庞大的软件。软件会囊括各种交错复杂的业务逻辑，阅读维护起来特别困难。前端项目体积滋长还会使编译时间越来越长，本地开发热更新时电脑吃力，卡机。 技术栈多样性公司在逐步扩大业务，永远有新的业务需要上线，永远有新的技术栈在尝试。庞大的单体软件很难同时运行多个技术栈，很难在业务中尝试使用新的技术，举步维艰。 跨团队开发若同一项目交给多个团队同时开发，由于是同一项目同一仓库，团队开发的资源并没有隔离经常会导致代码冲突，互相影响业务功能，造成开发风险。 技术方案 iframe 嵌套多个子项目 MPA 多子项目之前通过链接跳转 整合多个子项目资源，由主项目动态导航不同的子项目 这里重点介绍第三种 Single-SPA这种方案的重点是加载子应用资源，并根据路由进行资源导航，实现的方式市面上的工具各有不同比较知名的开源方案有： Single-SPA Qiankun icestark qiankun 使用了 single-SPA 的路由系统，且实现了一个 sandbox，用来隔离 js 运行环境。icestark 是飞冰团队的微前端方案，整体思路和前两者也比较接近。这里以 single-SPA 介绍其实现思路。 Single-SPA 将项目分为了主应用和子应用，主应用负责子应用导航，加载 JS、挂载应用等功能，而我们的主要业务代码放在子应用内。 主应用注册子应用示例 1234567891011121314151617181920212223import { registerApplication, start } from \"single-spa\";import * as isActive from \"./activity-functions\";registerApplication( \"@react-mf/navbar\", // System.import 是 system.js 提供的异步导入 js 模块的方法 () =&gt; System.import(\"@react-mf/navbar\"), isActive.navbar);registerApplication( \"@react-mf/people\", () =&gt; System.import(\"@react-mf/people\"), isActive.people);registerApplication( \"@react-mf/planets\", () =&gt; System.import(\"@react-mf/planets\"), isActive.planets);start(); 子应用导出示例 123456789101112131415import \"./set-public-path\";import React from \"react\";import ReactDOM from \"react-dom\";import singleSpaReact from \"single-spa-react\";import Root from \"./root.component\";const lifecycles = singleSpaReact({ React, ReactDOM, rootComponent: Root});export const bootstrap = lifecycles.bootstrap;export const mount = lifecycles.mount;export const unmount = lifecycles.unmount; 上面的两个代码示例介绍了 single-spa 的使用方法。那 single-spa 怎么实现微前端的呢？整体思路为： 子应用导出生命周期函数子应用需导出 bootstrap、mount、unmount、update（可选）函数，用于在 single-spa 生命周期中调用来挂载和卸载子应用 single-spa 提供 registerApplication 注册子应用。该方法第二个参数 applicationOrLoadingFn 用于异步导入子应用的资源包，示例中使用了 system.js 提供的 import 方法导入，当然别的异步导入方法也是支持的，只要返回一个 Promise 就行。该方法第三个参数 activityFn 用于确认是否激活该子应用。这是 single-spa 路由系统的关键，只有激活状态的子应用才会 mount。方法调用后会生成一个 app 对象并将 name, applicationOrLoadingFn, activityFn 等参数挂载到 app。 调用 reroute 方法挂载应用如果子应用还未调用 start 方法则会调用 loadApps 将所有激活状态（通过 activityFn）的子应用的 load 下来，并将子应用生命周期方法挂到 app 对象中。否则，调用 performAppChanges。该方法会先后调用需激活的子应用的 bootstrap、mount 方法完成子组件的挂载。 监听 hashchange, popstate 事件拦截路由变化路由变化时 single-spa 会重新调用 reroute 决定哪些子应用需要 unmount，哪些应用需要 mount。不仅如此，还会重写 window.addEventListener 和 window.removeEventListener 拦截所有 hashchange 和 popstate 的事件注册，使事件处理器在子应用在 single-spa 处理完子应用的 load、挂载或卸载之后才被调用。 Single-SPA 与 Qiankun qiankun 实现了一个 JS sandbox，避免子应用之间的环境污染 实现逻辑： 12345678910111213141516const rawWindow = window;const fakeWindow = Object.create(null) as Window;const sandbox: WindowProxy = new Proxy(fakeWindow, { set(_: Window, p: PropertyKey, value: any): boolean { // 省略... }, get(_: Window, p: PropertyKey): any { // 省略... }, has(_: Window, p: string | number | symbol): boolean { return p in rawWindow; },}); qiankun 通过 Proxy 拦截了 fakeWindow 对象，在使用他们编写的插件 import-html-entry load 子应用 js 时将其作为子应用的 window，并且每个子应用生成的对象都不同。这样，就实现了每个子应用的环境独立，避免变量污染。 1234567891011// get the entry html content and script executorconst { template: appContent, execScripts, assetPublicPath } = await importEntry(entry, { // compose the config getTemplate function with default wrapper getTemplate: flow(getTemplate, getDefaultTplWrapper(appName)), ...settings,});//省略部分代码...// get the lifecycle hooks from module exportslet { bootstrap: bootstrapApp, mount, unmount } = await execScripts(jsSandbox); JS Entry vs HTML Entry qiankun 采用 HTML Entry 作为资源注入方式，single-SPA 采用 JS Entry 方式注入。 JS Entry 方式要求主应用必须给子应用提供一个挂载的 DOM 节点；子应用需要将资源（js、css 等）打包到一个文件，或者打包时将所有子应用的资源路径单独保存配置，在主应用引用； HTML Entry 方式则不需要单独提供挂载点，也不需要单独处理资源加载的问题，无论是挂载点还是资源都在 HTML 中，都能一次性全部解析到。qiankun 拉取和解析 html 还是使用 import-html-entry 完成的。","link":"/2020/03/27/Micro-frontend/"},{"title":"Mobx-react","text":"Mobx 是一种状态管理方案。不同于 redux 将状态定义为不可变状态，mobx 会自动收集依赖，以可变状态的方式直接修改原始状态，这点与 Vue 的状态管理很像。 在 es6 环境下，可以直接使用装饰器定义状态及方法： 1234567891011121314151617import { observable } from \"mobx\";class CounterStore { @observable count = 0; @action increase() { this.count++; } @action decrease() { this.count--; }}export default new CounterStore(); @action 用来定义状态修改方法，@observable 用来定义可观察对象。 在 react 中可使用 mobx-react 提供的 Provider 组件装载 store 123456789101112131415161718192021222324252627import React, { Component } from 'react';import { Provider, observer, inject } from 'mobx-react';import ReactDOM from 'react-dom';import store from './counter-store';@inject('store')@observerclass Counter extends Component { render() { return ( &lt;div&gt; 自动响应 @action 对状态的变更：{this.props.store.count} &lt;div&gt; &lt;button onClick={() =&gt; this.props.store.increase()}&gt;+&lt;/button&gt; &lt;button onClick={() =&gt; this.props.store.decrease()}&gt;-&lt;/button&gt; &lt;/div&gt; &lt;/div&gt; ) }}ReactDOM.render( &lt;Provider store={store}&gt; &lt;Counter /&gt; &lt;/Provider&gt;, document.getElementById('mount')); @inject 用于将 Provider 传入的 props 注入到组件中。这里可将 store 注入到 Provider 的子组件中，当然也支持多个 store 同时注入。","link":"/2019/09/23/Mobx-react/"},{"title":"如何设置 Node 的 header size","text":"Header size 是什么每当任何客户端向服务器发送请求时，它也会发送一些头信息，所有服务器都对头缓冲区有一些预定义的限制。如果头缓冲区大小超过预定义的限制服务器，它将拒绝客户端请求，NodeJS 从 v6.15.0、v8.14.0、v10.14.0、v11.3.0 版本显著减小了（从80KB到8KB）头缓冲区的大小。 为什么需要增加 header size可能很少有情况需要增加 header size，下面是可能需要调整 header size 的原因 应用集成了多种服务，如 google analytics 等，可能增加 header size 。 如果使用一些用户校验方式，如 JWT，它的 token 长度可能会使 header size 超过限制。 请求中有许多自定义 header。 cookies 数据太大。 如何修改 header size 可修改 npm script，增加 max-http-header-size 选项，也可直接在命令行运行该 script。 123scripts:{ node --max-http-header-size=16000 server.js} 如果使用 pm2，可增加 node-args 参数。 1pm2 start server.js --node-args=\"--max-http-header-size=16000\" 如果使用 pm2 配置文件启动项目, 可增加 node_args 选项。 12345678910111213module.exports = { apps : [{ name: \"app\", script: \"./server.js\", node_args: \"--max-http-header-size=16000\" env: { NODE_ENV: \"development\", }, env_production: { NODE_ENV: \"production\", } }]}","link":"/2020/11/19/Node-max-header-size/"},{"title":"CSS 粘性定位 position: sticky","text":"顾名思义，sticky 就是将某元素粘在某个位置的意思。这里不用固定而用”粘“是因为要”粘“住一个东西必须先与这个东西要有接触才能说得上粘住。 ”粘“针对两个物体，被粘物与粘结物。这里的被粘物指我们的元素，粘结物是滚动容器的边界（上下左右）。通常我们实现这个效果都会使用 JS 来监听滚动并计算滚动位置来实现。现在你可以通过 CSS 来实现，通过查看 caniuse 可知，兼容性不是太好，不过可以使用 polyfill。 一个简单的例子： 对于这个例子，滚动容器是 body，被粘物体是 nav，约束物是 .box。具体来说： sticky 定位是针对滚动过程中元素的显示效果。所以滚动是粘滞效果的触发先决条件。 约束物是被粘物的包含块，决定了元素应该粘滞在什么地方及约束了粘滞效果必须作用在内部。 被粘物表示是什么元素会产生粘滞效果。 定位过程是： 默认状态下，.box 的 margin-top：50px 大于 nav 的 top: 20px，此时 nav 正常显示。 在 body 中继续往下滚动，直到 nav 距离滚动容器顶部的距离等于 20px，来到了粘性边界，继续往下滚动，nav 就会粘在约束物 .box 的内部，跟着容器滚动而同步滚动，产生粘性效果。 继续往下滚动最终 nav 会接触到约束物 .box 的底部。 若继续往下滚动，由于约束物约束了被粘物体只能在内部产生粘性效果，nav 只能跟着 .box 一起消失在滚动容器视区里。","link":"/2020/03/10/Sticky/"},{"title":"Vue-Vnode","text":"Vnode 是 Vue 内部的核心数据结构，用来描述 DOM 及 Component 和其对应的各种状态，例如： 12345678910const elementVNode = { tag: 'div', data: { style: { width: '100px', height: '100px', backgroundColor: 'red' } }} Vnode 的创建 Vnode 是 render 函数的产物，不管是 Template 字符串还是单文件组件中的标签都会编译为 render 函数，在 mount 阶段将会组合并挂载为 DOM。 Vnode 也可以手动创建，通过 createElement(h) 可以手动创建一个 Vnode 对象，组件的 render 函数就是调用这个方法创建 Vnode。 Vnode 的作用 描述真实 DOM。 描述抽象内容（组件，Fragment 等）。 提高性能。在 patch 阶段可通过 Diff 算法减少 patch 范围，从而减少 DOM 操作，提高性能。 Vnode 的种类","link":"/2019/08/05/Vue-Vnode/"},{"title":"Vue-computed","text":"computed 与 data 类似，在 init 阶段的 initState 中初始化的： 1234567// 遍历 computed，，为子项创建 watcherwatchers[key] = new Watcher( vm, getter || noop, noop, computedWatcherOptions) 如果 key 不是 vm 的属性则会调用： 123456789if (!(key in vm)) { defineComputed(vm, key, userDef)} else if (process.env.NODE_ENV !== 'production') { if (key in vm.$data) { warn(`The computed property \"${key}\" is already defined in data.`, vm) } else if (vm.$options.props &amp;&amp; key in vm.$options.props) { warn(`The computed property \"${key}\" is already defined as a prop.`, vm) }} 在 defineComputed 中通过 defineProperty 给 vm 添加对应 computed key 的 getter 和 setter。 1234567891011121314151617181920212223242526272829303132export function defineComputed ( target: any, key: string, userDef: Object | Function) { const shouldCache = !isServerRendering() if (typeof userDef === 'function') { sharedPropertyDefinition.get = shouldCache ? createComputedGetter(key) : userDef sharedPropertyDefinition.set = noop } else { sharedPropertyDefinition.get = userDef.get ? shouldCache &amp;&amp; userDef.cache !== false ? createComputedGetter(key) : userDef.get : noop sharedPropertyDefinition.set = userDef.set ? userDef.set : noop } if (process.env.NODE_ENV !== 'production' &amp;&amp; sharedPropertyDefinition.set === noop) { sharedPropertyDefinition.set = function () { warn( `Computed property \"${key}\" was assigned to but it has no setter.`, this ) } } Object.defineProperty(target, key, sharedPropertyDefinition)} 调用createComputedGetter 创建 getter。当 computed 被使用时将会调用该 getter： 1234567891011121314function createComputedGetter (key) { return function computedGetter () { const watcher = this._computedWatchers &amp;&amp; this._computedWatchers[key] if (watcher) { if (watcher.dirty) { watcher.evaluate() } if (Dep.target) { watcher.depend() } return watcher.value } }} 所以： 页面更新时 Dep.target 设置为当前页面的 watcher。 引用 computed 值的地方会触发他的 getter，createComputedGetter 包装的函数就会被调用。 此时若 dirty 则会使 computedWatcher.evaluate 调用，在计算 computed 的值时就会将这个 computed 的值依赖添加到 computedWatcher 中，同时依赖中也会将这个 computedWatcher 添加到它的 订阅者收集器 中。 computedWatcher.evaluate 执行时会备份当前的 Dep.target（渲染watcher），在获取 computed 值的过程中 Dep.target 会设置为 computedWatcher，当获取到 computed 的值后会恢复为 Dep.target（渲染watcher）。 执行 computedWatcher.depend() 时，Dep.target 为 渲染watcher，作用是把当前 computedWatcher 的依赖全部添加进 渲染watcher，依赖也会将 渲染watcher 添加到它的 订阅者收集器 中。 这步的作用是，当 computedWatcher 的依赖变化时直接通知页面更新（渲染watcher），而不是通过 computed 变化后再通知页面去更新，一步到位。 流程图","link":"/2019/08/06/Vue-computed/"},{"title":"Vue defineReactive","text":"大致执行过程依赖收集 在 initState 时，调用 initProps，initData 等 init 方法，通过 Observer 添加 getter 和 setter。 Observer 中调用 defineReactive 完成响应式对象初始化。 在 DefineReactive 中设置 getter，并在 getter 中通过 dep.depend() 收集依赖。 建立观察者 mountComponent 时会建立一个 watcher。 创建 watcher 时触发 updateComponent，从而触发组件依赖元素的 getter。 触发各个元素 getter 中的依赖收集。Dep.target 设置为当前 watcher。 Dep.target.addDep 会将各个元素依赖添加到当前 watcher。 Dep.target.addDep 调用时也会调用 dep.addSub 将 watcher 添加到 dep 的观察者列表中。 更新 当修改值时会触发元素的 setter。 通过 dep.notify() 通知 watcher。 在 watcher 的 update 中执行更新方法。 源码：defineReactive 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * Define a reactive property on an Object. */export function defineReactive ( obj: Object, key: string, val: any, customSetter?: ?Function, shallow?: boolean) { const dep = new Dep() const property = Object.getOwnPropertyDescriptor(obj, key) if (property &amp;&amp; property.configurable === false) { return } // cater for pre-defined getter/setters const getter = property &amp;&amp; property.get const setter = property &amp;&amp; property.set if ((!getter || setter) &amp;&amp; arguments.length === 2) { val = obj[key] } let childOb = !shallow &amp;&amp; observe(val) Object.defineProperty(obj, key, { enumerable: true, configurable: true, get: function reactiveGetter () { const value = getter ? getter.call(obj) : val // Dep.target 在 mountComponent 中设置 if (Dep.target) { // 收集依赖 dep.depend() if (childOb) { childOb.dep.depend() if (Array.isArray(value)) { dependArray(value) } } } return value }, set: function reactiveSetter (newVal) { const value = getter ? getter.call(obj) : val /* eslint-disable no-self-compare */ if (newVal === value || (newVal !== newVal &amp;&amp; value !== value)) { return } /* eslint-enable no-self-compare */ if (process.env.NODE_ENV !== 'production' &amp;&amp; customSetter) { customSetter() } // #7981: for accessor properties without setter if (getter &amp;&amp; !setter) return if (setter) { setter.call(obj, newVal) } else { val = newVal } childOb = !shallow &amp;&amp; observe(newVal) //当设置值时通知 dep dep.notify() } })} 源码：Dep 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273import type Watcher from './watcher'import { remove } from '../util/index'let uid = 0/** * 定义可观测对象，允许多次订阅 * 是响应式的核心部分 * 在对象 getter 中调用来观测对象元素 * 实际上是对 watcher 的管理 */export default class Dep { static target: ?Watcher; id: number; subs: Array&lt;Watcher&gt;; constructor () { this.id = uid++ this.subs = [] } /** * 在 watcher 中调用了此方法，用来收集订阅者 * */ addSub (sub: Watcher) { // 记录观察者 this.subs.push(sub) } removeSub (sub: Watcher) { remove(this.subs, sub) } /** * 在对象元素的 getter 中调用 * 由于 mountComponent 时添加了 watcher * 在 Watcher 的 constructor 中： * 1. 将此 watcher 设置为了 Dep.target， * 2. 执行表达式，触发表达式依赖元素的 getter */ depend () { if (Dep.target) { // 添加当前依赖到 watcher Dep.target.addDep(this) } } notify () { // stabilize the subscriber list first const subs = this.subs.slice() for (let i = 0, l = subs.length; i &lt; l; i++) { // 设置值时会调用 watcher 的 update，执行 update 策略 subs[i].update() } }}/** * target 是当前活动的 watcher * 在使用中同一时间只有一个 watcher 被使用 */Dep.target = nullconst targetStack = []export function pushTarget (_target: ?Watcher) { if (Dep.target) targetStack.push(Dep.target) Dep.target = _target}export function popTarget () { Dep.target = targetStack.pop()}","link":"/2019/07/31/Vue-defineReactive/"},{"title":"Vue-nextTick","text":"在 Vue 中 nextTick 实际上是一个 microTask（在 2.5 中曾被替换为 macroTask 实现，2.6 中又恢复为 microTask），源码位于 src/core/util/next-tick.js， 123456789101112131415161718192021222324export function nextTick (cb?: Function, ctx?: Object) { let _resolve callbacks.push(() =&gt; { if (cb) { try { cb.call(ctx) } catch (e) { handleError(e, ctx, 'nextTick') } } else if (_resolve) { _resolve(ctx) } }) if (!pending) { pending = true timerFunc() } // $flow-disable-line if (!cb &amp;&amp; typeof Promise !== 'undefined') { return new Promise(resolve =&gt; { _resolve = resolve }) }} 如上，可看到，nextTick 会将回调函数放入 callbacks 数组，等到执行时会依次全部执行完。这是为什么 nextTick 能将更新合并，他将回调都添加到数组，等到主线程执行完成后即会同时处理 callbacks 中的回调。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364// Here we have async deferring wrappers using microtasks.// In 2.5 we used (macro) tasks (in combination with microtasks).// However, it has subtle problems when state is changed right before repaint// (e.g. #6813, out-in transitions).// Also, using (macro) tasks in event handler would cause some weird behaviors// that cannot be circumvented (e.g. #7109, #7153, #7546, #7834, #8109).// So we now use microtasks everywhere, again.// A major drawback of this tradeoff is that there are some scenarios// where microtasks have too high a priority and fire in between supposedly// sequential events (e.g. #4521, #6690, which have workarounds)// or even between bubbling of the same event (#6566).let timerFunc// The nextTick behavior leverages the microtask queue, which can be accessed// via either native Promise.then or MutationObserver.// MutationObserver has wider support, however it is seriously bugged in// UIWebView in iOS &gt;= 9.3.3 when triggered in touch event handlers. It// completely stops working after triggering a few times... so, if native// Promise is available, we will use it:/* istanbul ignore next, $flow-disable-line */if (typeof Promise !== 'undefined' &amp;&amp; isNative(Promise)) { const p = Promise.resolve() timerFunc = () =&gt; { p.then(flushCallbacks) // In problematic UIWebViews, Promise.then doesn't completely break, but // it can get stuck in a weird state where callbacks are pushed into the // microtask queue but the queue isn't being flushed, until the browser // needs to do some other work, e.g. handle a timer. Therefore we can // \"force\" the microtask queue to be flushed by adding an empty timer. if (isIOS) setTimeout(noop) } isUsingMicroTask = true} else if (!isIE &amp;&amp; typeof MutationObserver !== 'undefined' &amp;&amp; ( isNative(MutationObserver) || // PhantomJS and iOS 7.x MutationObserver.toString() === '[object MutationObserverConstructor]')) { // Use MutationObserver where native Promise is not available, // e.g. PhantomJS, iOS7, Android 4.4 // (#6466 MutationObserver is unreliable in IE11) let counter = 1 const observer = new MutationObserver(flushCallbacks) const textNode = document.createTextNode(String(counter)) observer.observe(textNode, { characterData: true }) timerFunc = () =&gt; { counter = (counter + 1) % 2 textNode.data = String(counter) } isUsingMicroTask = true} else if (typeof setImmediate !== 'undefined' &amp;&amp; isNative(setImmediate)) { // Fallback to setImmediate. // Techinically it leverages the (macro) task queue, // but it is still a better choice than setTimeout. timerFunc = () =&gt; { setImmediate(flushCallbacks) }} else { // Fallback to setTimeout. timerFunc = () =&gt; { setTimeout(flushCallbacks, 0) }} 这部分时用于产生一个 延迟 函数 timerFunc，依次判定 Promise/MutationObserver/setImmediate，若都不存在则会使用 setTimeout 来实现。从源码可看出，在没有原生 microTask 时会使用 macroTask。 附常见异步任务方法： 任务类型 方法 微任务 setTimeout setInterval setImmediate script MessageChannel 宏任务 Promise MutationObserver Object.observe(废弃) process.nextTick（node）","link":"/2019/08/15/Vue-nextTick/"},{"title":"浅谈 DI(依赖注入)","text":"文章参考：https://zhuanlan.zhihu.com/p/311184005项目参考：darukjs InversifyJS 依赖注入是 IoC(控制反转) 的一种实现方式，通过依赖注入可以动态的将某种依赖关系注入到对象中，而不用手动一个个实例化。在依赖注入中，将实例化对象这个步骤交给外部（IoC 容器），即为控制反转。 一. 为什么需要依赖注入传统面向对象开发中，当两个类之间存在依赖关系时会直接在类的内部创建另一个的实例，导致两个类之间形成耦合关系。实际情况往往多个类之间会存在交叉依赖关系，一个类会被多个其它类依赖。这时如果类的功能有修改，则可能需要把所有依赖该类的地方统统改一遍。 如同上面解释的那样，A 和 B 两个类可能存在一种关系为 A 依赖于 B，例如： 12345678910111213141516// b.tsclass B { constructor() { }}// a.tsclass A { b: B; constructor() { this.b = new B(); }}// main.tsconst a = new A(); 此时如果如果有一个新需求，需要 B 初始化时传入一个新的参数 p，此时 B 为： 1234567// b.tsclass B { p: number; constructor(p: number) { this.p = p; }} B 修改后那么所有实例化 B 的地方都需要添加参数。 A 构造函数中实例化 B 时也需要传入参数 p；A 中的 p 并非凭空生成，也需要实例化 A 时传入参数，再将参数传给 B 的构造函数。此时 A 为： 1234567// a.tsclass A { b:B; constructor(p: number) { this.b = new B(p); }} 由上面的例子我们知道，修改 B 就需要修改 A，如果依赖层数很深则可能行程一条 修改链，由修改的那一层一直到表层。 二. 怎么实现 IoC 怎么解耦 上诉情况产生的原因是由于 A 需要 B 的实例，实现时选择直接在 A 中实例化 B，那么 A 实际上依赖的是 B 这个类（构造器）而非 B 的实例。A 并不关心 B 的实例在何时何地以何种方式构造出来。基于这个原因我们其实可以做以下改变： 12345678910111213141516171819// b.tsclass B { p: number; constructor(p: number) { this.p = p; }}// a.tsclass A { private b:B; constructor(b: B) { this.b = b; }}// main.tsconst b = new B(10);const a = new A(b); 这个例子中，我们将 A、B 各自独立的实例化，在 A 中直接传入 B 的实例，而非 B 的参数，这样当依赖项 B 有任何改变时，A 不需要做任何变化。 容器 上面的例子里我们实现了将 A 和 B 解耦，A 不再因为 B 改变而改变了。但如果还有一个类需要 B 的话仍然需要再次实例化 B，这样的地方越多，那么我们维护 B 的成本也就越高。我们很容易可以想到，要是将所有的依赖都统一管理，使用的时候不去 new 实例，而是直接拿到已经 new 好的实例，就解决了这个问题。 先新建一个容器类： 12345678910111213141516171819class Container { instanceMap = new Map() bind(id: string, clazz: any, constructorArgs: Array&lt;any&gt;) { this.instanceMap.set(id, { clazz, constructorArgs }) } get&lt;T&gt;(id: string): T { const target = this.instanceMap.get(id); const { clazz, constructorArgs } = target; const inst = Reflect.construct(clazz, constructorArgs); // Reflect.construct 类似 new 操作符 return inst }}export default new Container() 原来 A、B 的代码即可改为： 123456789101112131415161718192021// b.tsclass B { p: number; constructor(p: number) { this.p = p; }}// a.tsclass A { private b:B; constructor() { this.b = container.get('b'); // 此处通过容器注入 }}// main.tsimport container from './container.ts'// 绑定到容器container.bind('a', A);container.bind('b', B, [10]); 到此我们实现了一个容器，通过容器实现类和类之间的解耦。从功能上说，上面的实现就是一种 IoC， 将实例化的过程交给容器实现，而非类内部。但整个实现过程还是略显复杂，类需要手动绑定到容器， 依赖需要手动到容器上获取；如果这些步骤能自动实现，就能减少重复的代码，解放我们的双手。 实际上大部分框架中的 DI（依赖注入）就是为了完成这件事。 三. DIDI 即依赖注入，是 IoC 的一种实现方式，通过 DI，我们可以将依赖注入给调用方，不需要调用方主动去获取依赖。结合上文，为实现 DI，我们还需要完成以下两件事： 需要将类自动绑定到容器。 需自动将依赖注入到属性上（如例子中 A 需要关联 B 的实例）。 针对问题 1，一般由两个方法，一是通过一个清单文件，将需要注入的类列举出来，然后框架统一注入到容器中。二是通过注解（装饰器）直接在类中标识，然后逐一注入到容器中——本例采用的方式。针对问题 2，可以通过装饰器将容器收集到的类实例化到对应的对象属性上 这里使用装饰器进行依赖注册及注入，这种方式在使用时更为方便，当增加新的类文件时完全不用做任何操作，可以自动完成类注册到容器。下面我们来完成一个 DI 实例： Reflect Metadata 上面我们说 “针对问题一可以通过在类中标识，从而完成注入类到容器”，Reflect Metadata 即是用来标识类的。不止如此，我们将依赖注入到实例中时仍然需要它。 简单点理解，Reflect Metadata 就是用来在某一对象上写入一些数据，但是这些数据不能直接读取出来，也不影响对象的正常使用，等到我们需要的时候又可以通过 Reflect Metadata 提供的一些方法读出来。 想了解更多可以参考 Reflect Metadata Provide Provide 用来解决上面提到的问题一。这是一个装饰器，用它标识的 class 将会自动绑定到容器中，下面是 Provide 的实现 参考 inversify-binding-decorators 中 Provide 的简化实现 1234567891011121314151617181920212223242526272829import interfaces from \"./interfaces\";import { METADATA_KEY } from \"./constants\";import \"reflect-metadata\";export default function Provide(serviceIdentifier: string, args?: Array&lt;any&gt;) { return function (target: any) { // 当前 class 的信息 const currentMetadata: interfaces.ProvideSyntax = { id: serviceIdentifier, args: args || [], clazz: target }; // 已经收集的 class const previousMetadata: interfaces.ProvideSyntax[] = Reflect.getMetadata( METADATA_KEY.provide, Reflect ) || []; const newMetadata = [currentMetadata, ...previousMetadata]; // 将所有使用 Provide 装饰器标识的 class 都作为 Reflect 的元数据暂存 Reflect.defineMetadata( METADATA_KEY.provide, newMetadata, Reflect ); return target; };} 我们将所有需要绑定到容器的类都用 @Provide 去标记，收集并记录到 Reflect 对象中。如： 123456@Provide('b')export class B { constructor(p: number) { this.p = p; }} 但到这里收集依赖的部分还没完成，因为类都定义在文件内的。我们需要一个方法将需要的文件一次性都 require 进来，让依赖注册生效（@Provide）。下面的 binding 方法就是完成这件事，我们需要在应用的生命周期初始化阶段去手动调用它： 参考 darukjs 项目实现 12345678910111213141516171819// ./container.tsexport async function binding() { // 对目录没有限制，这里只是将常规目录作为示例 await _loadFile(join(__dirname, './middlewares')); await _loadFile(join(__dirname, './controllers')); await _loadFile(join(__dirname, './services')); container.load(buildProviderModule());}export async function _loadFile(path: string) { return recursive(path).then((files: Array&lt;any&gt;) =&gt; { return files .filter((file) =&gt; isJsTsFile(file)) .map((file) =&gt; file.replace(JsTsReg, '')) .forEach((path: string) =&gt; { require(path); }); }).catch(() =&gt; {});} 调用 binding 函数就会将 middlewares、controllers、services 目录中所有 @Provide 装饰的 class 都绑定到容器。 这里还缺两块，Container 的 load 方法，还有 buildProviderModule 函数。 buildProviderModule 函数就是为了从 Reflect 上拿到所有依赖项目。 buildProviderModule 参考 inversify-binding-decorators 的实现 1234567891011121314// ./container.ts/** * 省略已实现的代码 */function buildProviderModule() { return (bind: Function) =&gt; { let provideMetadata: interfaces.ProvideSyntax[] = Reflect.getMetadata(METADATA_KEY.provide, Reflect) || []; provideMetadata.map(metadata =&gt; bind( metadata.id, metadata.clazz, metadata.args )); };} 上面代码中的核心就是 Reflect.getMetadata(METADATA_KEY.provide, Reflect)，对比 Provide 中的这部分 12345Reflect.defineMetadata( METADATA_KEY.provide, newMetadata, Reflect) 我们大致就能摸清依赖注册的原理，@Provide 通过 Reflect.defineMetadata 完成收集。 buildProviderModule 方法中通过 Reflect.getMetadata 拿到收集到的类交给 container.load 完成依赖注册。 Container.load 如下： 1234567export class Container { // ...省略前面已实现的代码 public load(register) { // 注意，这里只是简化的例子 register(this.bind) }} Inject 前一步我们完成了依赖注册，将所有 待依赖 的 class 都在 container 中保存起来。接下来就是最后一步：在需要依赖的地方注入依赖项。 我们要做到的就是在类初始化时能自动拿到依赖对象的实例，不需要在依赖对象初始化时传参。我们已经将所有相关类都注册到 container 中，要使用某个类时，只要将 container 中对应的类实例化给相应属性即可。有了上面 Provide 的经验我们很容易就可以想到，通过装饰器很容易办到。 1234567891011121314151617181920212223242526272829303132333435// ./inject.tsimport container from './container'const INJECTION = Symbol.for(\"INJECTION\");export default function Inject(serviceIdentifier: string) { return function (proto: any, key: string) { let resolve = () =&gt; { // 从 container 中取值 return container.get(serviceIdentifier); }; function getter() { // 缓存值 if (!Reflect.hasMetadata(INJECTION, this, key)) { Reflect.defineMetadata(INJECTION, resolve(), this, key); } if (Reflect.hasMetadata(INJECTION, this, key)) { return Reflect.getMetadata(INJECTION, this, key); } else { return resolve(); } } function setter(newVal: any) { Reflect.defineMetadata(INJECTION, newVal, this, key); } Object.defineProperty(proto, key, { configurable: true, enumerable: true, get: getter, set: setter }); };} Inject 通过设置属性的 getter 和 setter 拦截属性的获取和设置。获取时从 container 中拿到依赖对应依赖，设置时则替换当前依赖的缓存值，等到下次获取时使用这个设置的新值。 经过上面的设置，原来 A、B 的例子即可改为： 1234567891011121314151617181920// 全局共用const container = new Container();// ./services/b.ts@Proivde('b', [10])class B { constructor(p: number) { this.p = p; }}// ./services/a.ts@Proivde('a')class A { @Inject('b') private b:B;}// ./main.tsbinding()console.log(container.get('a')); // =&gt; A { b: B { p: 10 } } 尾巴IoC 最早运用在后端服务上，随着时间的推移，像 Angular 这样的优秀框架实现了前端的 IoC，也给前端提出了新要求。技术思想是不分前后端的，不管是 MVC、IoC、AOP 抑或是别的，这些业界的经典设计，是一个在前后端都通用的思想或范式。我们不能给自己的技术设限，优秀的思想永远都是学习的目标。 前端在近些年日新月异，我们需要拥抱变化，融入变化；在未知的技术面前虚心学习是技术进阶的必经之路。 相关示例. di-example","link":"/2020/11/27/DI/"},{"title":"Git内部存储原理","text":"转载源：Git内部存储原理 目录 Git 目录结构 Git 目录结构 Git Object存储方式 总结 参考 Git是程序员工作中使用频率非常高的工具，要提高日常的工作效率，就需要熟练掌握Git的使用方法。相对于传统的版本控制系统而言，Git更为强大和灵活，其各种命令和命令参数也非常多，如果不了解Git的内部原理，要把Git使用得顺手的话非常困难。本文将用一个具体的例子来帮助理解Git的内部存储原理,加深对Git的理解，从掌握各种Git命令，以在使用Git进行工作时得心应手。 Git 目录结构Git的本质是一个文件系统，其工作目录中的所有文件的历史版本以及提交记录(Commit)都是以文件对象的方式保存在.git目录中的。 首先创建一个work目录，并采用git init命令初始化git仓库。该命令会在工作目录下生成一个.git目录，该目录将用于保存工作区中所有的文件历史的历史版本，提交记录，branch，tag等信息。 123$ mkdir work$ cd work$ git init 其目录结构如下： ├── branches 不这么重要，暂不用管 ├── config git配置信息，包括用户名，email，remote repository的地址，本地branch和remote | branch的follow关系 ├── description 该git库的描述信息，如果使用了GitWeb的话，该描述信息将会被显示在该repo的页面上 ├── HEAD 工作目录当前状态对应的commit，一般来说是当前branch的head，HEAD也可以通过git checkout 命令被直接设置到一个特定的commit上，这种情况被称之为 detached HEAD ├── hooks 钩子程序，可以被用于在执行git命令时自动执行一些特定操作，例如加入changeid │ ├── applypatch-msg.sample │ ├── commit-msg.sample │ ├── post-update.sample │ ├── pre-applypatch.sample │ ├── pre-commit.sample │ ├── prepare-commit-msg.sample │ ├── pre-push.sample │ ├── pre-rebase.sample │ └── update.sample ├── info 不这么重要，暂不用管 │ └── exclude ├── objects 保存git对象的目录，包括三类对象commit,tag, tree和blob │ ├── info │ └── pack └── refs 保存branch和tag对应的commit ├── heads branch对应的commit └── tags tag对应的commitGit Object存储方式目前objects目录中还没有任何内容，我们创建一个文件并提交。 12345678$ echo \"my project\" &gt; README$ echo \"hello world\" &gt; src/file1.txt$ git add .$ git commit -sm \"init commit\"[master (root-commit) b767d71] init commit 2 files changed, 2 insertions(+) create mode 100644 README create mode 100644 src/file1.txt 从打印输出可以看到，上面的命令创建了一个commit对象，该commit包含两个文件。 查看.git/objects目录，可以看到该目录下增加了5个子目录 06，3b， 82， b7， ca，每个子目录下有一个以一长串字母数字命令的文件。 .git/objects ├── 06 │ └── 5bcad11008c5e958ff743f2445551e05561f59 ├── 3b │ └── 18e512dba79e4c8300dd08aeb37f8e728b8dad ├── 82 │ └── 424451ac502bd69712561a524e2d97fd932c69 ├── b7 │ └── 67d7115ef57666c9d279c7acc955f86f298a8d ├── ca │ └── 964f37599d41e285d1a71d11495ddc486b6c3b ├── info └── pack说明：Git Object目录中存储了三种对象：Commit， tree和blob。Git为对象生成一个文件，并根据文件信息生成一个 SHA-1 哈希值作为文件内容的校验和，创建以该校验和前两个字符为名称的子目录，并以 (校验和) 剩下 38 个字符为文件命名 ，将该文件保存至子目录下。 查看Git Object存储内容通过 git cat-file命令可以查看Git Object中存储的内容及对象类型，命令参数为Git Object的SHA-1哈希值，即目录名+文件名。在没有歧义的情况下，不用输入整个Hash，输入前几位即可。 当前分支的对象引用保存在HEAD文件中，可以查看该文件得到当前HEAD对应的branch，并通过branch查到对应的commit对象。 1234$ cat .git/HEADref: refs/heads/mastercat .git/refs/heads/masterb767d7115ef57666c9d279c7acc955f86f298a8d 使用 -t 参数查看文件类型： 12$ git cat-file -t b767d7commit 使用 -p 参数可以查看文件内容： 12345678$ git cat-file -p b767d7tree ca964f37599d41e285d1a71d11495ddc486b6c3bauthor Huabing Zhao &lt;zhaohuabing@gmail.com&gt; 1548055516 +0800committer Huabing Zhao &lt;zhaohuabing@gmail.com&gt; 1548055516 +0800init commitSigned-off-by: Huabing Zhao &lt;zhaohuabing@gmail.com&gt; 可以看出这是一个commit对象，commit对象中保存了commit的作者，commit的描述信息，签名信息以及该commit中包含哪些tree对象和blob对象。 b767d7这个commit中保存了一个tree对象，可以把该tree对象看成这次提交相关的所有文件的根目录。让我们来看看该tree对象中的内容。 123$ git cat-file -p ca964f100644 blob 065bcad11008c5e958ff743f2445551e05561f59 README040000 tree 82424451ac502bd69712561a524e2d97fd932c69 src 可以看到该tree对象中包含了一个blob对象，即README文件；和一个tree对象，即src目录。 分别查看该blob对象和tree对象，其内容如下： 1234$ git cat-file -p 065bcamy project$ git cat-file -p 824244100644 blob 3b18e512dba79e4c8300dd08aeb37f8e728b8dad file1.txt 查看file1.txt的内容。 12$ git cat-file -p 3b18e51hello world 从上面的实验我们可以得知，git中存储了三种类型的对象，commit，tree和blob。分别对应git commit，此commit中的目录和文件。这些对象之间的关系如下图所示。 HEAD---&gt; refs/heads/master--&gt; b767d7(commit) + | v ca964f(tree) + | +---------+----------+ | | v v 065bca(blob) 824244(tree) README src + | v 3b18e5(blob) file1.txt Git branch和tag从refs/heads/master的内容可以看到，branch是一个指向commit的指针，master branch实际是指向了b767d7这个commit。 1234567891011$ git checkout -b workSwitched to a new branch 'work'$ tree .git/refs/.git/refs/├── heads│ ├── master│ └── work└── tags$ cat .git/refs/heads/work .git/refs/heads/masterb767d7115ef57666c9d279c7acc955f86f298a8db767d7115ef57666c9d279c7acc955f86f298a8d 上面的命令创建了一个work branch。从其内容可以看到，该branch并没有创建任何新的版本文件，和master一样指向了b767d7这个commit。 从上面的实验可以看出，一个branch其实只是一个commit对象的应用，Git并不会为每个branch存储一份拷贝，因此在git中创建branch几乎没有任何代价。 在work branch上进行一些修改，然后提交。 123456$ echo \"new line\" &gt;&gt; src/file1.txt$ echo \"do nothing\" &gt;&gt; Makefile$ git commit -sm \"some change\"[work 4f73993] some change 2 files changed, 2 insertions(+) create mode 100644 Makefile 查看当前的HEAD和branch内容。 12345$ cat .git/HEADref: refs/heads/workhuabing@huabing-xubuntu:~/work$ cat .git/refs/heads/work .git/refs/heads/master4f73993cf81931bc15375f0a23d82c40b3ae6789b767d7115ef57666c9d279c7acc955f86f298a8d 可以看到HEAD指向了work branch,而work branch则指向了4f73993这个commit，master branch指向的commit未变化，还是b767d7。 查看4f73993这个commit对象的内容。 123456789$ git cat-file -p 4f73993tree 082b6d87eeddb15526b7c920e21f09f950f78b54parent b767d7115ef57666c9d279c7acc955f86f298a8dauthor Huabing Zhao &lt;zhaohuabing@gmail.com&gt; 1548069325 +0800committer Huabing Zhao &lt;zhaohuabing@gmail.com&gt; 1548069325 +0800some changeSigned-off-by: Huabing Zhao &lt;zhaohuabing@gmail.com&gt; 可以看到commit有一个parent字段，指向了前一个commi b767d7。该commit也包含了一个tree对象，让我们看看其中的内容。 1234567$ git cat-file -p 082b6d100644 blob 8cc95f278445722c59d08bbd798fbaf60da8ca14 Makefile100644 blob 065bcad11008c5e958ff743f2445551e05561f59 README040000 tree 9aeacd1fa832ca167b0f72fb1d0c744a9ee1902f src$ git cat-file -p 9aeacd100644 blob 79ee69e841a5fd382faef2be2f2eb6e836cc980a file1.txt 可以看到该tree对象中包含了该版本的所有文件和目录，由于README没有变化，还是指向的065bca这个blob对象。Makefile是一个新建的blob对象，src和file1.txt则指向了新版本的对象。 增加了这次commit后，git中各个对象的关系如下图所示： (parent) HEAD--&gt; refs/heads/work--&gt; 4f7399(commit) +-------&gt; b767d7(commit)&lt;---refs/heads/master + + | | v v 082b6d(tree) ca964f(tree) + + | | +-----------------------------+ +--------+-----------+ | | | | | v v v v v 9aeacd(tree) 8cc95f(blob) 065bca(blob) 824244(tree) src (version 2) Makefile README src (version 1) + + | | v v 79ee69(blob) 3b18e5(blob) file1.txt (version 2) file1.txt (version 1)从上图可以看到，Git会为每次commit时修改的目录/文件生成一个新的版本的tree/blob对象，如果文件没有修改，则会指向老版本的tree/blob对象。而branch则只是指向某一个commit的一个指针。即Git中整个工作目录的version是以commit对象的形式存在的，可以认为一个commit就是一个version，而不同version可以指向相同或者不同的tree和blob对象，对应到不同版本的子目录和文件。如果某一个子目录/文件在版本间没有变化，则不会为该子目录/文件生成新的tree/blob对象，不同version的commit对象会指向同一个tree/object对象。 Tag和branch类似，也是指向某个commit的指针。不同的是tag创建后其指向的commit不能变化，而branch创建后，其指针会在提交新的commit后向前移动。 1234$ git tag v1.0$ cat .git/refs/tags/v1.0 .git/refs/heads/work4f73993cf81931bc15375f0a23d82c40b3ae67894f73993cf81931bc15375f0a23d82c40b3ae6789 可以看到新创建的v1.0 tag和work branch都是指向了4f7399这个commit。 Git Stash实现原理Git stash的功能说明：经常有这样的事情发生，当你正在进行项目中某一部分的工作，里面的东西处于一个比较杂乱的状态，而你想转到其他分支上进行一些工作。问题是，你不想提交进行了一半的工作，否则以后你无法回到这个工作点。解决这个问题的办法就是git stash命令。 “‘储藏”“可以获取你工作目录的中间状态——也就是你修改过的被追踪的文件和暂存的变更——并将它保存到一个未完结变更的堆栈中，随时可以重新应用。 Git是如何实现Stash的呢？理解了Commit, Tree, Blog这三种Git存储对象，我们就可以很容易理解Git Stash的实现原理。因为和bransh及tag类似，Git Stash其实也是通过Commit来实现的。 通过实验来测试一下： 12$ echo \"another line\" &gt;&gt; src/file1.txt$ git stash 通过上面的命令，我们在file1.txt中增加了一行，然后通过git stash命令将这些改动“暂存”在了一个“堆栈”中，让我们来看看.git目录发生了什么变化。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071$ tree .git/.git/├── branches├── COMMIT_EDITMSG├── config├── description├── HEAD├── hooks│ ├── applypatch-msg.sample│ ├── commit-msg.sample│ ├── post-update.sample│ ├── pre-applypatch.sample│ ├── pre-commit.sample│ ├── prepare-commit-msg.sample│ ├── pre-push.sample│ ├── pre-rebase.sample│ └── update.sample├── index├── info│ └── exclude├── logs│ ├── HEAD│ └── refs│ ├── heads│ │ ├── master│ │ └── work│ └── stash├── objects│ ├── 06│ │ └── 5bcad11008c5e958ff743f2445551e05561f59│ ├── 08│ │ └── 2b6d87eeddb15526b7c920e21f09f950f78b54│ ├── 11│ │ └── a6d1031e4fa2d4da0b6303dd74ed8e85c54057│ ├── 33│ │ └── f98923002cd224dabf32222c808611badd6d48│ ├── 3b│ │ └── 18e512dba79e4c8300dd08aeb37f8e728b8dad│ ├── 4f│ │ └── 73993cf81931bc15375f0a23d82c40b3ae6789│ ├── 6a│ │ ├── 1474c4da0653af0245970997b6fab0a0a7c1df│ │ └── d88760c3be94d8cb582bf2d06b99083d034428│ ├── 75│ │ └── e170cc1d928ae5a28547b4a3f2f3394a675b9a│ ├── 79│ │ └── ee69e841a5fd382faef2be2f2eb6e836cc980a│ ├── 82│ │ └── 424451ac502bd69712561a524e2d97fd932c69│ ├── 8c│ │ └── c95f278445722c59d08bbd798fbaf60da8ca14│ ├── 90│ │ └── c43dbb1e71c271510994d6b147c425cbffa673│ ├── 9a│ │ └── eacd1fa832ca167b0f72fb1d0c744a9ee1902f│ ├── b7│ │ └── 67d7115ef57666c9d279c7acc955f86f298a8d│ ├── ca│ │ └── 964f37599d41e285d1a71d11495ddc486b6c3b│ ├── e8│ │ └── 83e779eb08e2d9bca1fc1ee722fc80addac312│ ├── info│ └── pack├── ORIG_HEAD└── refs ├── heads │ ├── master │ └── work ├── stash └── tags └── v1.0 可以看到objects目录中增加了一些对象文件，refs中增加了一个stash文件。通过命令查看该文件内容： 1234567891011121314151617181920$ cat .git/refs/stash11a6d1031e4fa2d4da0b6303dd74ed8e85c54057$ git cat-file -p 11a6tree 90c43dbb1e71c271510994d6b147c425cbffa673parent 4f73993cf81931bc15375f0a23d82c40b3ae6789parent 6a1474c4da0653af0245970997b6fab0a0a7c1dfauthor Huabing Zhao &lt;zhaohuabing@gmail.com&gt; 1548326421 +0800committer Huabing Zhao &lt;zhaohuabing@gmail.com&gt; 1548326421 +0800WIP on work: 4f73993 some change$ git cat-file -p 90c4100644 blob 8cc95f278445722c59d08bbd798fbaf60da8ca14 Makefile100644 blob 065bcad11008c5e958ff743f2445551e05561f59 README040000 tree 33f98923002cd224dabf32222c808611badd6d48 src$ git cat-file -p 33f9100644 blob 75e170cc1d928ae5a28547b4a3f2f3394a675b9a file1.txt$ git cat-file -p 75e1hello worldnew lineanother line 从命令行输出可以看到,git stash实际上创建了一个新的commit对象11a6d1, 该commit对象的父节点为4f7399。commit对象中包含了修改后的file1.txt blob对象75e170。通过git log可以查看： 1234567$ git log --oneline --graph stash@{0}* f566001 WIP on work: 4f73993 some change|\\| * 0796ced index on work: 4f73993 some change|/* 4f73993 some change* b767d71 init commit 备注：git stash生成的commit对象有两个parent，一个是前面一次git commit命令生成的commit，另一个对应于保存到stage中的commit。 从该试验可以得知，git stash也是以commit，tree和object对象实现的。Git stash保存到“堆栈”中的修改其实一个commit对象。 Git reset 实现原理在进行一些改动以后并通过git commit 将改动的代码提交到本地的repo后，如果你测试发现刚才的改动不合理，希望回退刚才的改动，应该如何处理？ 我们先提交一个错误的改动： 12345$ echo \"I did something wrong\" &gt;&gt; src/file1.txt$ git add .$ git commit -sm \"This commit should not be there\"[work ccbc363] This commit should not be there 1 file changed, 1 insertion(+) 你可以通过git revert回退刚才的改动，或者修改代码后再次提交，但这样的话你的提交log会显得非常凌乱；如果不想把中间过程的commit push到远程仓库，可以通过git reset 回退刚才的改动。 先查看目前的log 123456789101112131415161718192021222324$ git logcommit ccbc3638142191bd68454d47a0f67fd12519806bAuthor: Huabing Zhao &lt;zhaohuabing@gmail.com&gt;Date: Fri Jan 25 12:35:31 2019 +0800 This commit should not be there Signed-off-by: Huabing Zhao &lt;zhaohuabing@gmail.com&gt;commit 4f73993cf81931bc15375f0a23d82c40b3ae6789Author: Huabing Zhao &lt;zhaohuabing@gmail.com&gt;Date: Mon Jan 21 19:15:25 2019 +0800 some change Signed-off-by: Huabing Zhao &lt;zhaohuabing@gmail.com&gt;commit b767d7115ef57666c9d279c7acc955f86f298a8dAuthor: Huabing Zhao &lt;zhaohuabing@gmail.com&gt;Date: Mon Jan 21 15:25:16 2019 +0800 init commit Signed-off-by: Huabing Zhao &lt;zhaohuabing@gmail.com&gt; 通过 git reset回退到上一个commit。注意这里HEAD是一个指向当前branch最后一个commit指针，因此HEAD~1表示之前的一个commit。git reset命令也可以直接使用commit号作为命令参数。 1234567891011121314151617181920$ git reset HEAD~1Unstaged changes after reset:M src/file1.txt$ git logcommit 4f73993cf81931bc15375f0a23d82c40b3ae6789Author: Huabing Zhao &lt;zhaohuabing@gmail.com&gt;Date: Mon Jan 21 19:15:25 2019 +0800 some change Signed-off-by: Huabing Zhao &lt;zhaohuabing@gmail.com&gt;commit b767d7115ef57666c9d279c7acc955f86f298a8dAuthor: Huabing Zhao &lt;zhaohuabing@gmail.com&gt;Date: Mon Jan 21 15:25:16 2019 +0800 init commit Signed-off-by: Huabing Zhao &lt;zhaohuabing@gmail.com&gt; 可以看到刚才的commit被回退了，但修改的文件还存在，处于Unstaged状态，你可以对这些文件进行改动后再次提交。 如果你不想保留修改的文件，可以使用–hard参数直接回退到指定的commit，该参数会将HEAD指向该commit，并且工作区中的文件也会和该comit保持一致，该commit后的修改会被直接丢弃。 12345$ git reset HEAD --hardHEAD is now at 4f73993 some change$ git statusOn branch worknothing to commit, working directory clean Git object存储方式Git object是通过下面的方式处理并存储在git内部的文件系统中的： 首先创建一个header，header的值为 “对象类型 内容长度\\0” 将header和文件内容连接起来，计算得到其SHA-1 hash值 将连接得到的内容采用zlib压缩 将压缩后的内容写入到以 “hash值前两位命令的目录/hash值后38位命令的文件” 中 可以通过Ruby手工创建一个 Git object 来验证上面的步骤。 123456789101112131415161718192021222324$ irbirb(main):001:0&gt; content = \"what is up, doc?\" //文件内容=&gt; \"what is up, doc?\"irb(main):002:0&gt; header = \"blob #{content.length}\\0\" //创建header=&gt; \"blob 16\\u0000\"irb(main):003:0&gt; store = header + content //拼接header和文件内容=&gt; \"blob 16\\u0000what is up, doc?\"irb(main):004:0&gt; require 'digest/sha1'=&gt; trueirb(main):005:0&gt; sha1 = Digest::SHA1.hexdigest(store)=&gt; \"bd9dbf5aae1a3862dd1526723246b20206e5fc37\" //计算得到hash值irb(main):006:0&gt; require 'zlib'=&gt; trueirb(main):007:0&gt; zlib_content = Zlib::Deflate.deflate(store) //压缩header+文件内容 =&gt; \"x\\x9CK\\xCA\\xC9OR04c(\\xCFH,Q\\xC8,V(-\\xD0QH\\xC9O\\xB6\\a\\x00_\\x1C\\a\\x9D\"irb(main):008:0&gt; path = '.git/objects/' + sha1[0,2] + '/' + sha1[2,38]=&gt; \".git/objects/bd/9dbf5aae1a3862dd1526723246b20206e5fc37\" //通过hash值计算文件存储路径irb(main):009:0&gt; require 'fileutils'=&gt; trueirb(main):010:0&gt; FileUtils.mkdir_p(File.dirname(path)) //写文件=&gt; [\".git/objects/bd\"]irb(main):011:0&gt; File.open(path, 'w') { |f| f.write zlib_content }=&gt; 32irb(main):012:0&gt; 文件以及写入到Git的内部存储中，我们尝试通过git cat-file 验证并读取该文件内容： 12$ git cat-file -p bd9dbf5aae1a3862dd1526723246b20206e5fc37what is up, doc? 可以看到，可以通过git cat-file文件读取该文件内容，因此该文件是一个合法的git object，和通过git 命令写入的文件格式相同。 总结Git围绕三种Object来实现了版本控制以及Branch，Tag等机制。 Commit: Commit可以看作Git中一个Version的所有目录和文件的Snapshot，可以通过git checkout 查看任意一个commit中的内容。 Tree: 目录对象，内部包含目录和文件 Blob: 文件对象，对应一个文件 理解了Git object的存储机制，就可以理解Git的各个命令的实现原理，更好地使用Git来实现源代码管理。 参考 https://git-scm.com/book/en/v2/Git-Internals-Git-Objects","link":"/2020/03/30/Git/"}],"tags":[{"name":"tokenize","slug":"tokenize","link":"/tags/tokenize/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"原理","slug":"原理","link":"/tags/原理/"},{"name":"转载","slug":"转载","link":"/tags/转载/"},{"name":"微前端","slug":"微前端","link":"/tags/微前端/"},{"name":"micro frontend","slug":"micro-frontend","link":"/tags/micro-frontend/"},{"name":"react","slug":"react","link":"/tags/react/"},{"name":"mobx","slug":"mobx","link":"/tags/mobx/"},{"name":"Node","slug":"Node","link":"/tags/Node/"},{"name":"css","slug":"css","link":"/tags/css/"},{"name":"position","slug":"position","link":"/tags/position/"},{"name":"sticky","slug":"sticky","link":"/tags/sticky/"},{"name":"vue","slug":"vue","link":"/tags/vue/"},{"name":"DI","slug":"DI","link":"/tags/DI/"}],"categories":[{"name":"源码阅读","slug":"源码阅读","link":"/categories/源码阅读/"}]}